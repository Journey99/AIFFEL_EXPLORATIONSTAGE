{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f5abc36",
   "metadata": {},
   "source": [
    "# 6. 영화리뷰 텍스트 감성분석하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b246952",
   "metadata": {},
   "source": [
    "## 학습 목표\n",
    "- 텍스트 데이터를 머신러닝 입출력용 수치데이터로 변환하는 과정을 이해한다.\n",
    "- RNN의 특징을 이해하고 시퀀셜한 데이터를 다루는 방법을 이해한다.\n",
    "- 1-D CNN으로도 텍스트를 처리할 수 있음을 이해한다.\n",
    "- IMDB와 네이버 영화리뷰 데이터셋을 이용한 영화리뷰 감성 분류 실습을 진행한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126d9dcd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae04272",
   "metadata": {},
   "source": [
    "## 6.4 텍스트를 숫자로 표현하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1efcf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "751319bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a7a119",
   "metadata": {},
   "source": [
    "- 텍스트를 숫자로 바꾸려면 위의 딕셔너리가 {텍스트:인덱스} 구조여야 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b0c820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8e40ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "803756d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f13f34bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e35c68e",
   "metadata": {},
   "source": [
    "- DECODE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b4bf31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "145d7064",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a4725b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3f2e231",
   "metadata": {},
   "source": [
    "## 6.5 Embedding 레이어의 등장\n",
    "- 단어와 그 단어의 의미를 나타내는 벡터를 짝짓는다\n",
    "- 단어의 의미를 나타내는 벡터를 훈련 가능한 파라미터로 놓고 이를 딥러닝을 통해 학습해서 최적화하게 된다\n",
    "-  Tensorflow, Pytorch 등의 딥러닝 프레임워크들은 이러한 의미 벡터 파라미터를 구현한 Embedding 레이어를 제공한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f57e4ec",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/original_images/E-9-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811df4aa",
   "metadata": {},
   "source": [
    "-  word_to_index('great')는 1918\n",
    "- 'great'라는 단어의 의미 공간상의 워드 벡터(word vector)는 Lookup Table 형태로 구성된 Embedding 레이어의 1919번째 벡터가 된다\n",
    "- 위 그림에서는 1.2, 0.7, 1.9, 1.5가 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "546f8c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n",
      "tf.Tensor(\n",
      "[[[-0.04218031 -0.02353637 -0.04403194 -0.03226653]\n",
      "  [-0.0221695   0.03075423 -0.00052952 -0.00596543]\n",
      "  [ 0.04849053  0.03169378  0.04382727  0.00294093]\n",
      "  [ 0.03111641 -0.02475123  0.0486166  -0.0328836 ]\n",
      "  [-0.005395    0.02586058  0.04243508 -0.00137381]]\n",
      "\n",
      " [[-0.04218031 -0.02353637 -0.04403194 -0.03226653]\n",
      "  [-0.0221695   0.03075423 -0.00052952 -0.00596543]\n",
      "  [ 0.01832732 -0.02341004 -0.02809111  0.03475522]\n",
      "  [-0.03435415  0.02261936 -0.01170069  0.01173165]\n",
      "  [-0.005395    0.02586058  0.04243508 -0.00137381]]\n",
      "\n",
      " [[-0.04218031 -0.02353637 -0.04403194 -0.03226653]\n",
      "  [-0.03275894  0.02647214  0.0199175  -0.0120442 ]\n",
      "  [-0.0221695   0.03075423 -0.00052952 -0.00596543]\n",
      "  [ 0.04849053  0.03169378  0.04382727  0.00294093]\n",
      "  [-0.0153426  -0.00753361  0.04647124  0.04048331]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f7d9d3",
   "metadata": {},
   "source": [
    "### tf.keras.preprocessing.sequence.pad_sequences\n",
    "- raw_inputs의 벡터의 길이가 다 다르기 때문에 문장 뒤에 패딩(\\<PAD>)을 추가하여 길이를 일정하게 맞춰준다\n",
    "\n",
    "### output의 shape=(3,4,5)\n",
    "- 3은 입력문장 개수, 5는 입력문장의 최대 길이, 4는 워드 벡터의 차원 수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24907c88",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30dc294",
   "metadata": {},
   "source": [
    "## 6.6 시퀀스 데이터를 다루는 RNN\n",
    "- 텍스트 데이터를 다루는 데 주로 사용되는 딥러닝 모델은 Recurrent Neural Network(RNN)\n",
    "- RNN은 시퀀스 형태의 데이터를 처리하기에 최적인 모델로 알려져 있다\n",
    "    - 시퀀스 데이터란 바로 입력이 시간 축을 따라 발생하는 데이터\n",
    "    - RNN은 시간의 흐름에 따라 새롭게 들어오는 입력에 따라 변하는 현재 상태를 묘사하는 state machine으로 설계되었기 때문"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff3817cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db71efc7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b8112c",
   "metadata": {},
   "source": [
    "## 6.7 꼭 RNN이어야 할까?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c669da9a",
   "metadata": {},
   "source": [
    "### 1-D CNN(1-D Convolution Neural Network)\n",
    "- 문장 전체를 한꺼번에 한 방향으로 길이 7짜리 필터로 스캐닝 하면서 7단어 이내에서 발견되는 특징을 추출하여 그것으로 문장을 분류하는 방식으로 사용\n",
    "- CNN계열은 RNN계열보다 병렬처리가 효율적이기 때문에 학습 속도도 훨씬 빠름\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2880bad3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2836e54e",
   "metadata": {},
   "source": [
    "### GlobalMaxPooling1D()\n",
    "- 하나만 사용하는 방법도 있다\n",
    "-  이 방식은 전체 문장 중에서 단 하나의 가장 중요한 단어만 피처로 추출하여 그것으로 문장의 긍정/부정을 평가하는 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6a7eb28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685e7d7d",
   "metadata": {},
   "source": [
    "- 이 외에도 1-D CNN과 RNN 레이어를 섞어 쓴다거나, FFN(FeedForward Network) 레이어만으로 구성하거나, 혹은 최근 각광받고 있는 Transformer 레이어를 쓰는 등 매우 다양한 시도를 해볼 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47864a49",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6fff9e",
   "metadata": {},
   "source": [
    "## 6.8 IMDB 데이터셋 분석\n",
    "- IMDb Large Movie Dataset은 50000개의 영어로 작성된 영화 리뷰 텍스트로 구성되어 있으며, 긍정은 1, 부정은 0의 라벨이 달려있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8efdd41d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 0s 0us/step\n",
      "17473536/17464789 [==============================] - 0s 0us/step\n",
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(\"훈련 샘플 개수: {}, 테스트 개수: {}\".format(len(x_train), len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5d2537",
   "metadata": {},
   "source": [
    "### imdb.load_data()\n",
    "- 인자로 num_words를 사용하면 이 데이터에서 등장 빈도 순위로 몇 등까지의 단어를 사용할 것인지를 의미\n",
    "- 10000만큼 word_to_index 딕셔너리까지 생성된 형태로 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8abc9bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "# 확인\n",
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8d678d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "1646592/1641221 [==============================] - 0s 0us/step\n",
      "1654784/1641221 [==============================] - 0s 0us/step\n",
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# IMDB 데이터셋에는 encode에 사용한 딕셔너리까지 함께 제공\n",
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3eb68742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_to_word[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925d8226",
   "metadata": {},
   "source": [
    "### word_to_index\n",
    "- IMDb 텍스트 데이터셋의 단어 출현 빈도 기준으로 내림차수 정렬되어 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ec48160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "05bf9adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469d009",
   "metadata": {},
   "source": [
    "### pad_sequences\n",
    "- 데이터셋 상의 문장의 길이를 통일하는 것을 잊어서는 안된다\n",
    "- 문장 최대 길이 maxlen의 값 설정도 전체 모델 성능에 영향을 미치게 된다\n",
    "- 이 길이도 적절한 값을 찾기 위해서는 전체 데이터셋의 분포를 확인해 보는 것이 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7b809a23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print('전체 문장의 {}%가 maxlen 설정값 이내에 포함됩니다. '.format(np.sum(num_tokens < max_tokens) / len(num_tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a4c4fb",
   "metadata": {},
   "source": [
    "### padding\n",
    "-  padding 방식을 문장 뒤쪽('post')과 앞쪽('pre') 중 어느 쪽으로 하느냐에 따라 RNN을 이용한 딥러닝 적용 시 성능 차이가 발생한다\n",
    "- 두 가지 방식을 한 번씩 다 적용해서 RNN을 학습시켜 보면서 그 결과를 비교해 보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0820db44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5067e13",
   "metadata": {},
   "source": [
    "- RNN은 입력데이터가 순차적으로 처리되어, 가장 마지막 입력이 최종 state 값에 가장 영향을 많이 미치게 된다. 그러므로 마지막 입력이 무의미한 padding으로 채워지는 것은 비효율적이다. 따라서 'pre'가 훨씬 유리하며, 10% 이상의 테스트 성능 차이를 보이게 된다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a715e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f818ab38",
   "metadata": {},
   "source": [
    "## 6.9 IMDB 영화리뷰 감성분석 (2) 딥러닝 모델 설계와 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1376767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 8)                 800       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,881\n",
      "Trainable params: 160,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9051e54b",
   "metadata": {},
   "source": [
    "### 검증데이터셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6445413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ed7f07",
   "metadata": {},
   "source": [
    "### model 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8373ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 15s 45ms/step - loss: 0.6932 - accuracy: 0.5063 - val_loss: 0.6932 - val_accuracy: 0.5009\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6930 - accuracy: 0.5167 - val_loss: 0.6933 - val_accuracy: 0.5002\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6927 - accuracy: 0.5242 - val_loss: 0.6933 - val_accuracy: 0.5009\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6923 - accuracy: 0.5202 - val_loss: 0.6928 - val_accuracy: 0.5097\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6913 - accuracy: 0.5245 - val_loss: 0.6925 - val_accuracy: 0.5043\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6878 - accuracy: 0.5213 - val_loss: 0.6909 - val_accuracy: 0.5118\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6840 - accuracy: 0.5139 - val_loss: 0.6908 - val_accuracy: 0.5069\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6737 - accuracy: 0.5328 - val_loss: 0.6966 - val_accuracy: 0.5067\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6665 - accuracy: 0.5299 - val_loss: 0.7064 - val_accuracy: 0.5036\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6605 - accuracy: 0.5309 - val_loss: 0.7028 - val_accuracy: 0.5062\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6614 - accuracy: 0.5240 - val_loss: 0.7012 - val_accuracy: 0.5064\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6917 - accuracy: 0.5085 - val_loss: 0.6960 - val_accuracy: 0.5022\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 1s 28ms/step - loss: 0.6834 - accuracy: 0.5189 - val_loss: 0.6931 - val_accuracy: 0.5043\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6749 - accuracy: 0.5273 - val_loss: 0.6905 - val_accuracy: 0.5057\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6677 - accuracy: 0.5329 - val_loss: 0.6897 - val_accuracy: 0.5068\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6625 - accuracy: 0.5351 - val_loss: 0.6920 - val_accuracy: 0.5077\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6593 - accuracy: 0.5328 - val_loss: 0.6965 - val_accuracy: 0.5128\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6576 - accuracy: 0.5297 - val_loss: 0.6984 - val_accuracy: 0.5126\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 1s 30ms/step - loss: 0.6553 - accuracy: 0.5362 - val_loss: 0.7023 - val_accuracy: 0.5084\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 1s 29ms/step - loss: 0.6543 - accuracy: 0.5301 - val_loss: 0.7046 - val_accuracy: 0.5078\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "176d8d4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 5s - loss: 0.6980 - accuracy: 0.5122\n",
      "[0.6979725956916809, 0.5122399926185608]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4aa75e6",
   "metadata": {},
   "source": [
    "### 그래프로 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "686499d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f95d8d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d81ef2",
   "metadata": {},
   "source": [
    "- Training and validation loss를 그려 보면, 몇 epoch까지의 트레이닝이 적절한지 최적점을 추정해 볼 수 있다. validation loss의 그래프가 train loss와의 이격이 발생하게 되면 더 이상의 트레이닝은 무의미해지게 마련이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "073bae64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2013bc82",
   "metadata": {},
   "source": [
    "## 6.10 IMDB 영화리뷰 감성분석 (3) Word2Vec의 적용\n",
    "- Embedding 레이어 : 우리가 가진 사전의 단어 개수 X 워드 벡터 사이즈만큼의 크기를 가진 학습 파라미터\n",
    "- 감성 분류 모델이 학습이 잘 되었다면, Embedding 레이어에 학습된 우리의 워드 벡터들도 의미 공간상에 유의미한 형태로 학습되었을 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76ba8150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7583b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223ee88b",
   "metadata": {},
   "source": [
    "- gensim에서 제공하는 패키지를 이용해, 위에 남긴 임베딩 파라미터를 읽어서 word vector로 활용할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65b83de9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10075034,  0.07879648, -0.10418931, -0.03518716, -0.08327173,\n",
       "       -0.01003464,  0.10568539, -0.02627708, -0.0046684 , -0.11101151,\n",
       "       -0.01745053, -0.06190516, -0.01544061, -0.02168071,  0.03893534,\n",
       "       -0.03751646], dtype=float32)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37a9b22",
   "metadata": {},
   "source": [
    "### similar_by_word()\n",
    "- 워드 벡터가 의미 벡터 공간상에 유의미하게 학습되었는지 확인하는 방법 중에, 단어를 하나 주고 그와 가장 유사한 단어와 그 유사도를 확인하는 방법은"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "efccd8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('responsible', 0.8309895992279053),\n",
       " ('earnest', 0.823240339756012),\n",
       " ('ian', 0.8174790740013123),\n",
       " ('policemen', 0.8097823858261108),\n",
       " ('crazed', 0.7917754650115967),\n",
       " ('heck', 0.7744620442390442),\n",
       " ('honeymoon', 0.773127555847168),\n",
       " ('opening', 0.7692908048629761),\n",
       " ('easily', 0.7576017379760742),\n",
       " ('prequel', 0.7525036931037903)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5027b8f",
   "metadata": {},
   "source": [
    "- love라는 단어와 유사한 다른 단어를 그리 잘 찾았다고 느껴지지는 않는다\n",
    "- 감성 분류 태스크를 잠깐 학습한 것만으로 워드 벡터가 유의미하게 학습되기는 어려운 것이다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988816fe",
   "metadata": {},
   "source": [
    "###  구글에서 제공하는 Word2Vec이라는 사전학습된(Pretrained) 워드 임베딩 모델을 가져다 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c20d454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05290e61",
   "metadata": {},
   "source": [
    "- 300dim의 벡터로 이루어진 300만 개의 단어\n",
    "- KeyedVectors.load_word2vec_format 메서드로 워드 벡터를 로딩할 때 가장 많이 사용되는 상위 100만 개만 limt으로 조건을 주어 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "86477742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loved', 0.6907791495323181),\n",
       " ('adore', 0.6816873550415039),\n",
       " ('loves', 0.661863386631012),\n",
       " ('passion', 0.6100708842277527),\n",
       " ('hate', 0.600395679473877),\n",
       " ('loving', 0.5886635780334473),\n",
       " ('affection', 0.5664337873458862),\n",
       " ('undying_love', 0.5547304749488831),\n",
       " ('absolutely_adore', 0.5536840558052063),\n",
       " ('adores', 0.5440906882286072)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54d56d0",
   "metadata": {},
   "source": [
    "### 이전에 학습했던 모델의 임베딩 레이어를 Word2Vec의 것으로 교체하여 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4df0b439",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aead3369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f70f14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 14s 83ms/step - loss: 0.6898 - accuracy: 0.5318 - val_loss: 0.6819 - val_accuracy: 0.5600\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.6665 - accuracy: 0.5958 - val_loss: 0.6605 - val_accuracy: 0.6125\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.6114 - accuracy: 0.6910 - val_loss: 0.5839 - val_accuracy: 0.6990\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.4601 - accuracy: 0.8112 - val_loss: 0.3935 - val_accuracy: 0.8330\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.3060 - accuracy: 0.8769 - val_loss: 0.3128 - val_accuracy: 0.8682\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.2239 - accuracy: 0.9126 - val_loss: 0.3128 - val_accuracy: 0.8654\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.1705 - accuracy: 0.9397 - val_loss: 0.3205 - val_accuracy: 0.8689\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.1226 - accuracy: 0.9607 - val_loss: 0.3069 - val_accuracy: 0.8761\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.0880 - accuracy: 0.9767 - val_loss: 0.3060 - val_accuracy: 0.8813\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.0599 - accuracy: 0.9883 - val_loss: 0.3249 - val_accuracy: 0.8792\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.0397 - accuracy: 0.9941 - val_loss: 0.3424 - val_accuracy: 0.8796\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.0261 - accuracy: 0.9980 - val_loss: 0.3605 - val_accuracy: 0.8793\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.0169 - accuracy: 0.9991 - val_loss: 0.3877 - val_accuracy: 0.8803\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 66ms/step - loss: 0.0122 - accuracy: 0.9996 - val_loss: 0.3980 - val_accuracy: 0.8802\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0086 - accuracy: 0.9997 - val_loss: 0.4169 - val_accuracy: 0.8801\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0064 - accuracy: 0.9999 - val_loss: 0.4289 - val_accuracy: 0.8802\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0048 - accuracy: 0.9999 - val_loss: 0.4563 - val_accuracy: 0.8798\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.8804\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.8798\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 67ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.8802\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "475490b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5487 - accuracy: 0.8683\n",
      "[0.5487269163131714, 0.8683199882507324]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45cfce9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
